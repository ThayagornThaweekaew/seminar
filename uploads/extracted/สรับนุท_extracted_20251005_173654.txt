DecisionTreeOfDecisionTreeAndhungryis/NoTypeofclassificatioHave123 $GotoSleepyof~NoRandomForestGotoresturantBuyahamburger-สร้าาเต้นไม้หลายๆต้นจาก Gataset ตั้งเดิมมาใใช้(เรียกว่าBootstrap-ในแต่จะต้นจะสุ่ม feat+แม่นยํา/แข็งแแกร่งกว่าา ต้นไม้เดี่ยว Docisi+ลดoverfittinNaireBayeกฎของเบยPSY1):PCXIY) ·P(Y)PCX)PCYH) = ความน่าจะเป็น class 4 เมื่อรx เร็วเมาเหมาะกรับข้อมูลจําน·ใช้กับ teet classification ได้ดี PCY) = ความน่าจะเป็นล่วงหน้าของP(x) = ความน่าจะเป็นล่วงหน้า ของข้KNNCK-NearestNeighbors &algorithmlearningofSupervisedLearning,classification1 เข้าใจน·Regression" ไม่ต้องฝึกโม↑ปรับK7 เพื่อควบคุม ความยืCARTAlgorithmClassificationandRegressionTre

ImpurityEntropyConditionalProbabilitEntroP = -(5,CloseEs +#loadSampleSpace<Gain =EC51 -InfonctionA = { (-1,2)IXithe:10Information =#".../↓3 :ลูกเต๋า2 ลูก = 36
+8 =(X1,+17 /Xi>1,NativeBaySPCA) :↑6Bayes'TheoremPC8):#PCDisease /PosPCr>+:10↑=PCPosIDisease) .&(Disease)EPCOIAL⊥ค่เที่ 8, >PCPOS):~As (3,31,(0, 0),16,03=

classificationAccuracy =TP++N+ P+EP +FN+TNOA -PopulationMisclassificationrate·PopulationInitializatioErrorrate =- randominitialization >แบบสุTP+EP +TN+FNPrecisio= TO- heuristicinitialization -> บางส่วนอิงตามความรูTP+FPRecall :#·Population Model (รูปแบVaประชากรF-measure=25Recall +Precision-steadystateเปลี่ยนแปลงทีละTP+FNRecall +Precisio-Generationalประชากรรทั้งหมดถูกแทนด้วจ ปรจาก Generatio!on OliviDNA เก็บข้อมูลลักษณะไว้ / 10,1RealValve·↑#⑥Genotypeตัวแทนขอคําตอย Solution)ในรูปแบบโค้ดเป็น binary, striny, array ? ลง InPermutaPhenotype คําตอบจริิงที่สามารถนงไช้ในนประเมินหหรือใช้้งานได้ (ที่ได้หลังจากแปล↓8:101010 -X:&2P:SA) ->PS42) =1764Encoding วิธีที่ใช้เปลี่ยนคําตอ-เป็น เช่นตัวเลข)ให้กลายเป็น Genotype PhenotyDecoling วิธีทที่ใใช้เปลียน Genotype เป็น Thenotypee 010Fitness function ฟัังก์ชั่น ประเมินคความ"ดี" ของคําตตอบ11ตวะชชุดใช้ตัดสินว่าGenotyp2 ไ⊥ fitness สูงยยิ่งมีโอกาส ถูกเลือกGeneticOperatorsจําลอกระบวนการวิวัฒนาการของธรรselectio&CrossoveMutatio#Genotype - (Decoling) ->Phenotype->Fitnessfunction >Selection ->Crossover aMutation ->NewGenotypedisc, ********

OverfittingandUnterfittinginMachineLearninTradeoff (การแลกเปลี่ยbias (ความเอนเอียของโมเด-ลดbiasโดยทําให้ขัมเดลซับซ-ความแตกต่างระหว่างค่าที่่โมเดลททํานนายกvariance มักเพ-เกิดขขึ้นเมื่อโมเดลเรียบง่ายเกินไป จนไมม่สามารถจับความซิบซ-ลดvarianceโดยทําให้โมเคลง่า-มักเกิด Underfittibias มักเพ-โมเดลจะะพลาดเยอะทั้งบนข้อมูลฝึก (training) และข้อมูเทดสอบ (testing)- หVariance (ความแปรปรวณ ของโมเดล-โมเดลเขียนรู้้ ไวเก-ข้มเดลเรียนรู ้รายละเอียดและ noise ใในขข้อมูลฝึกมเกเกินไป จนเสียความสสามารกในกการท-มักเกิด Overfitti-ผลคือ-ทํานาย ข้้อมูลฝึกได้ดดีมาก" แต่ข้ออมูล- Ex.ใช้สมการซิบซ้วนมากจนผ่่านทุกจุดขของข้อมูลฝึก แต่ไไม่สามารถทาย
LowDiasLowVarianceHighVariancePruning (การติดแต่งโมเ:อนเขะ: :::::::·post-ติดข้อมูลที่ไม่จํา เป็นเช่น ทํานายการซื้อIcecr #↑·:::·::::::overfittingunberfittingข้อมูล วัน เกิด... เHighDias··Regularizatio↑Goodbalance-ไข่่ LinearRegressionทําน-Featureเยอะเกินใช้ Lasso(L1 Regr.ทําใให้คค่าที่ไม่จําเป็นกโครตยากกกก(RemoveFeatureTrainwithmoredata/-ลบทที่ไม่จ-เพิ่่ม fatnsBagging (BootstrapAggregating)⊥Ensemble. Learninบเควเข้าด้วยกวัน เพื่่ออให้้ผ-ลดการรเกิดoverfittin-RandomforestBoostin-เพิ่มความสามารถการทํานายของโมเดล(weak learner) -> strong lear2 ทําให้ทํานายแม

ConfusionMatrix2class =2x2Sensitivity (Recall)และSpecificityประเมินประสิทธิิภาพโม3Class:3x3-Sensitivity /Recall (TPR)จัดส่วนของ positive claเช่น จากผู ้้ป่วยจริงๆ ตรวจเโมเดลททํานาผลลัพ-FalseNegativeRate (FNA)สิดร่วนของ positiveclassที่TPYesYes&-Specificity (TNRTสััดร่วนของ negative classที่ถTNYesFDNoNบอกข้อผิดพลาดขของโมเดล, claFNNoYesใช้คํานวรค่าต่างๆเช่น Accuracy, Precision, Rโมเดลตรวจไข้หวัดใหญ่ 10CalculationusingConfusionMatrix· จริเช่วย 40 > ทํานายถูก 33(TP), พลาด 3· จริงไม่ช่วย 60--7 ททํานายถูก SO STN) ,พลาด10ClassificationAccuracyca-โมเดลททํานายตกริ/จากข้อมวทั้งหมดู จจํานวนทํานนายว่าถถูกกตAccuracy :#30 =83%TP+FP+=NATN2 จํานวนข้อมูลทัPrecision =33 =77.8%MisclassificationRate(ErrorRate35+10-อัตราาที่โมเดลททํานRecall :#=87.3%Error Rate : 1 -Accuracy-จํานวนที่ททํานาย= FP +FNfl-score =200.778.0.875 ~82.2/TP +TN +=PtFN -> จน.ข้อมูลทั้0.778 +0.875Precision - สิ่งที่ชมเดลบอกว่า"ใช่" มีเท่่าไห-ความแม่นยําเชิง-ในบรรดาาข้อมูลที่โมเดลทํานายว่าเป็นบอก มีีเท่าไหร่Precision =TRTP+FDงงละซี ๊Recall (sensitivity /TruePositiveRate) -ในสั่นทที่ถูกกจริง มมีีเท่าไหร่ที-ในบรรดาข้อมููลที่เป็็น บอกจริง:โมเดลสามารถจจับได้ถูกRecall =EN=-- measure (F1Scorel-ค่าที่รวม Precision และ Recall เข้าด้วยกันเพื่อวิดความสมาตุลระหFM =2xPrecision =RecalPrecision +Recal

EntropyทEntrophic =ดImpurity ความไม่บริสสุทธขอ-Spiloge (Pi)ถ้าในNobe-มีข้อมูล Classimpurity ติ:สูง : แImpurity = (100%) -> แยก class ชัดเจ&แยถ้้าในnode-มีหลาย claช่วย บอกช่่,ทอโนีี้บอกคําไดEmporite เพิ่ม-> ข้อมูลปนเยอะแยก claisออแศไหECST = - (PCYes)log.Plyes) +P(NO)LogPINOL)ECoutlook =Sunny ) = -I/092-3lose3 =0971Elpropsi9ECoutlook :Overcast) = -1log11 -0log20 =ESoutlook =Sunny) = -1loset -5loge2 =0.001Information = ความน่าจะเป็นของ class นั้น = Entropy ของ Class นั้น + ... Class อื่นๆ Information fromGainCoutlook) =ECS) =1CoutlookICoutlook) =1 =0.971 +&20 +·1 20.271 =0.0Gain (Outlook ) =ESS) -1loutlookExample -Blog -3logi=2 =0.991= 0.94 -0.693:0.247-10.4 . (-1,32193) + (0.6. 7.023696))=-0.328772 -0.042176InformationGain: 0.9709 -0.977⊥- ช่ว!เลือก feature:ที่ดีที่สุดในการ split แบ่งfeature⊥การสร้างtree featuลดImpurityของnodeได้เรWeather:Buy {:หาค่าา IGหลังจาก split ออกแต่ละ featOvercastเช่16 (weather) =13เอาweatherเบน-Roo16 (Temperature) =0.312ECB) = -109 -#Tags :0.918E (S) = -PEYes)logeP(Yes) -PCNO)LogePCNoECincome =Low) =-1lone -Blogs4 =0.918&(Age =Young) = -Eloge -Blog =1E (income =Refirm) = -1Logis -O loge·=·ECAge =Middle) = -bloger -Blog =0.81ECincome =High = -1loges -Glogi =·ECAge =016) = -1loght -I logd =0.8171 (income):#=0.918 +120 +100 =0.439ICAge) =1 1 =1 +1 1+0.81 +( 1081 =0.87gain(income ) =ECO) -1 Sincome=0.918-0.439 =0.459Gain (Age) =E (8) -1 (Age=0.918-0.874:0.04↑HCS) = -1 logs E -Blog :0.918H (Low ,Age =Young) =·incomH (Low ,Age >Mittle) ="LowthesiscialisIsagesกับ1SincomH CLow ,Age :High) =หาเพื่อ compareมาเป็น Roof nYesYes2.0 +2.1 +1.7 :0.667byMoto#YesมือN

Entropy = - (,loge)) +1loge (3):- 10.3. (-1) +0.S = (-17=> Yes: - -0.3-0.3=> Xe:- 1 -แยInformatioCataly =High) = - ( ,logn2 +IlogetICHw:DoneIt iColorto+hloa=- C0.66666667 -0.SUP963) +0.3333333 = (-1.5849639))=- ( 0.75 =-0.47SO2) +0.25 - (-2)=- - CO,2879718 -0.52832077)=0.21829217= 0.81127775ICstrby:Lou) = - (Closet +Ilose/1CHw =NotDona) = - (@2 login +Ilosc/:- 0.52832072 -0.3899718: - JO +Ol=0.97829217=Cataly) ==100.918292 +-0.91829-1SHw) =:0.8172777) +1 -0== 0.459146 +0.459146= 0.540851i0.918292GAINCStudy)21-0.918272GainCHW) =1 -0.540889: 0.081708=0.4S9182#HomeworkDon't-NotDoneHighLow 'NoYestheNo&มาจากYes1No1

=Genetical Algorithm หาคําตอบทที่ดีที่สุุด โดยใช้หหลักการพันธุุศาสนศาสตPopulationinitializationและnaturalSelection1.RandomInitializatioเพิ่มความเ-สร้าว solutionเริ่มต้นแบบสุ่มครอบคลุมทุกควาOptimization ทําใหดีที่สุดX -0 -13,Population =3,9,10,12.HerristicInitializatio011 อ->·/1|1/0chromosome-สร้าว solutionจากความรู↓PopulationMotelPopulatio(Castofchromosomes) {Gene1.Steadystate-แทนทที่เฉพาะขาว chromosome ใน populati1AllolePopulation come -> Gris chill 2 แทน 2 ตัวที่แย2.Generationa+ทั้งหหมดแต่จะ Generatpopulation10 ต. ->·vischillnoline10DNA เก็บข้อมูลลักษณะไว้ / 10,1RealValve·↑#⑥Genotypeตัวแทนขอคําตอย Solution)ในรูปแบบโค้ดเป็น binary, striny, array ? ลง InPermutaPhenotype↓คําตอบจริที่สามารถนนําไข้ในนประะเมินหรือใช้งงานได้(ที่ได้หลังจากแปล8:101010 -X:&2P:SA) ->PS42) =1764Encoding วิธีที่ใช้เปลี่ยนคําตอ-เป็น เช่นตัวเลข)ให้กลายเป็น Genotype PhenotyDecoling วิธีทที่ใใช้เปลียน Genotype เป็น Thenotypee 010Fitness function ฟัังก์ชั่น ประเมินคความ"ดี" ของคําตตอบ11ตวะชชุดใช้ตัดสินว่าGenotyp2 ไ⊥ fitness สูงยยิ่งมีโอกาส ถูกเลือกGeneticOperatorsจําลอกระบวนการวิวัฒนาการของธรร{ selectionCrossoveMutatio#Genotype - (Decoling) ->Phenotype->Fitnessfunction >Selection ->Crossover aMutation ->NewGenotype

&Aเลือเลือก เลืวิงParentSelectioไม่นเอ0123↑36itemnumber·FitnessProportionateSelectionเลือกparent โด(RouletteWheelSelection)โอการเลือก = Fitnes01011 101chromosomeผลรวมของFitnessทั้งห2983&02ProfitValues0 Stochastic Universal Sampling เหมือนRouletteแต่ใช้ pointer หลาCSUS)เลือกหลาย parentแขบวดvarianc733139WeightValvesโจทยo Tournament Selection เลือกก parentt โดยรุ่มกลุ่่มย่อย (tourknapsacle capacity = 13 - นํ้าหนักต้องแล้้วเลือก Fitness สููงสสุดใItem &*numberไมมาเลือกเพราะจะทําให้ weightProfit :+St+2 :18·RankSelectionprobabilityarankWeight =+1+948 :19Weight3 +143 =71·Itemnumber1,2,3GA-Crossoverเปลี่่ยนระหว่าง 2 paเป้าหมายเพื่ออรวมคุณสมบัติที่ดีของ parแบ่เกลา" 01292onepointCrossoverO12/3&->67834Chromosome216MultipointCrossoverOld3. As·MiSearch to s·-&segment =↑->123p/367819uniformCrossover·12345018323672945GA-Mutationเปลี่ยนค่า gene ของ chromosome แบททําหลังจาก crossover เพื่อสร้างความหลารุ ่ม flipbBitFlipMutatio00101101>00111107สุ่ม2 geneสลัย AlRandomResetting,SwapMutation1234567>1274564
⊥ScrambleMutation01234567ส่่มจัดล>036941278ส่มและ ReverInversionMutation012345678I>012453876

* GATerminationConditionเงื่อนไขที่ทําให้GA หGA-SurvivorSelection* AgeBasedSelection* ถ้าfitness waspopulationไไม่ดีขึ้นน ถึงจะห- จํากจัดออายุขอก chromosomeถ้าเกินที่กําหนดAFitnessBasedSelection-เลือกchromosomee ที่ fitne3) สูงรุตเข้า population ถัดไป -> populationchill -parent:12เลือกก 66 ที่ fitnoss ส* selectpopulation>fitnessfumc >Crossover amutation ->survivorselection->TerminateandReturnBestNaiveDaysWeatherPlay1SunnyP (Yes) =Go#อYesPCNO) =Conditionalprobability:Dayes'Theorem2sunny⊥YesSunnyPCAIS) =PCOIA)PCAPYes /Sunny ) =PCsonny/Yes)PCYesYes1Sunny↑(8↑sunny5SunnyNO=  " fr3 = probability ลูกเต๋า-Yes6Rainy&%No=(1,17, (1,2), (1,32, ...26,53,36,6737Rain=0.No8Rainyให้้ Aและ-8 เป็นเหตุการณ์ 2 เหตA =Gate)/x, +x2 =1039Rainy=- 60 %Yes8 =/(1,,+27/x,>x23N·10RainyYe:A: { (3,3), (4,6),16,473,hCA) =311OvercastYes12OvercastและPCAT = 37 อานนท์เกิดขึ้นอYes13Over cast:8 = { (2,1), (3,1), (3,27, . . .16,513,1 (8) =13.14OvercastYesและPCB) =บทนี้ง่ายS2 =PCA,>XeUX, +<2 =10)(= PCOIA)>  23,3), (4,61,76,433~:คาที่ x,>x2คือ 576,53 =PCX1+A =1017.3xel= PCAIP)=Is